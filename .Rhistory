data.mis$DemTVReg <- with(data.mis, impute(DemTVReg, 'random'))
data.mis$PromTime <- with(data.mis, impute(PromTime, 'random'))
data.mis$PromClass <- with(data.mis, impute(PromClass, 'random'))
data.mis$ID <- with(data.mis, impute(ID, 'random'))
data.mis$PromSpend <- with(data.mis, impute(PromSpend, 'random'))
data.mis$TargetBuy <- with(data.mis, impute(TargetBuy, 'random'))
organics<-data.mis
sapply(organics, function(x) sum(is.na(x)))
set.seed(42)
random <- runif(nrow(organics)) # create random numbers
orgrandom <- organics[order(random), ]
head(orgrandom)
orgtrain <- orgrandom[1:11110, ]
orgtest <- orgrandom[11111:22223, ]
table(orgtrain$TargetBuy)
orgtree <- rpart(TargetBuy ~ DemAffl+DemAge+DemClusterGroup+DemGender+DemReg+DemTVReg+PromClass+PromSpend+PromTime, data = orgtrain, method = "class")
rpart.plot(orgtree)
orgtrain$pred <- predict(orgtree, orgtrain, type = "class") #create a prediction using our tree
table(Actual = orgtrain$TargetBuy, Predicted = orgtrain$pred) #create a confusion matrix
orgtrain$correct <- orgtrain$TargetBuy == orgtrain$pred #create a new colum, TRUE if predicted = actual, otherwise FALSE
traincorrectcount <- length(which(orgtrain$correct))
trainincorrectcount <- nrow(orgtrain) - traincorrectcount
trainerrorrate <- trainincorrectcount/nrow(orgtrain)
trainaccuracy <- 1-trainerrorrate
orgtraintree <- rpart(TargetBuy ~ DemAffl+DemAge+DemClusterGroup+DemGender+DemReg+DemTVReg+PromClass+PromSpend+PromTime, data = orgtrain, method = "class")
rpart.plot(orgtraintree)
orgtrain <- testModelPerformance(orgtree, orgtrain, orgtrain$TargetBuy)
orgtest$pred <- predict(orgtree, orgtest, type = "class") #create a prediction using our tree
table(Actual = orgtest$TargetBuy, Predicted = orgtest$pred) #create a confusion matrix
orgtest$correct <- orgtest$TargetBuy == orgtest$pred #create a new colum, TRUE if predicted = actual, otherwise FALSE
testcorrectcount <- length(which(orgtest$correct))
testincorrectcount <- nrow(orgtest) - testcorrectcount
testerrorrate <- testincorrectcount/nrow(orgtest)
testModelPerformance <- function(model, dataset, target, prediction) {
if(missing(prediction))
{
print("here")
dataset$pred <- predict(model, dataset, type = "class")
}
else
{
print("here2")
dataset$pred <- prediction
}
writeLines("PERFORMANCE EVALUATION FOR")
writeLines(paste("Model:", deparse(substitute(model))))
writeLines(paste("Target:", deparse(substitute(target))))
writeLines("\n\nConfusion Matrix:")
confMatrix <- table(Actual = target, Predicted = dataset$pred)
truePos <- confMatrix[2,2]
falseNeg <- confMatrix[2,1]
falsePos <- confMatrix[1,2]
trueNeg <- confMatrix[1,1]
print(confMatrix)
writeLines("\n\n")
accuracy <- (truePos + trueNeg)/(truePos + falseNeg + falsePos + trueNeg)
sensitivity <- truePos/(truePos + falseNeg)
specificity <- trueNeg/(falsePos + trueNeg)
falsePosRate <- falsePos/(falsePos + trueNeg)
falseNegRate <- falseNeg/(truePos + falseNeg)
precision <- truePos/(truePos + falsePos)
writeLines(paste("Accuracy:", round(accuracy, digits = 4)))
writeLines(paste("Sensitivity:", round(sensitivity, digits = 4)))
writeLines(paste("Specificity:", round(specificity, digits = 4)))
writeLines(paste("False Positive Rate:", round(falsePosRate, digits = 4)))
writeLines(paste("False Negative Rate:", round(falseNegRate, digits = 4)))
writeLines(paste("Precision:", round(precision, digits = 4)))
dataset
}
llh <- function(y, py) {
sum(y * log(py) + (1-y) * log(1-py))
}
library(readxl)
data<-read_excel("~/Fall 2017 Semester/BUAN 6356 - Prof Bardhan/HW3/organics.xlsx")
set.seed(42)
data$DemCluster<-NULL
data$TargetAmt<-NULL
data$DemGender<-as.factor(data$DemGender)
data$DemClusterGroup<-as.factor(data$DemClusterGroup)
data$DemReg<-as.factor(data$DemReg)
data$DemTVReg<-as.factor(data$DemTVReg)
data$PromClass<-as.factor(data$PromClass)
table(data$TargetBuy)
head(data)
aggr_plot <- aggr(data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
sapply(data, function(x) sum(is.na(x)))
data.mis <- mice(data,m=5,maxit=5,meth='pmm',seed=500)
summary(data.mis)
organics <- complete(data.mis,1)
sapply(organics, function(x) sum(is.na(x)))
random <- runif(nrow(organics)) # create random numbers
orgrandom <- organics[order(random), ]
head(orgrandom)
orgtrain <- orgrandom[1:11110, ]
orgtest <- orgrandom[11111:22223, ]
table(orgtrain$TargetBuy)
orgtree <- rpart(TargetBuy ~ DemAffl+DemAge+DemClusterGroup+DemGender+DemReg+DemTVReg+PromClass+PromSpend+PromTime, data = orgtrain, method = "class")
orgtree
rpart.plot(orgtree)
orgtrain$pred <- predict(orgtree, orgtrain, type = "class") #create a prediction using our tree
table(Actual = orgtrain$TargetBuy, Predicted = orgtrain$pred) #create a confusion matrix
orgtrain$correct <- orgtrain$TargetBuy == orgtrain$pred #create a new column, TRUE if predicted = actual, otherwise FALSE
traincorrectcount <- length(which(orgtrain$correct))
trainincorrectcount <- nrow(orgtrain) - traincorrectcount
trainerrorrate <- trainincorrectcount/nrow(orgtrain)
trainaccuracy <- 1-trainerrorrate
orgtrain <- testModelPerformance(orgtree, orgtrain, orgtrain$TargetBuy)
orgtest$pred <- predict(orgtree, orgtest, type = "class") #create a prediction using our tree
table(Actual = orgtest$TargetBuy, Predicted = orgtest$pred) #create a confusion matrix
orgtest$correct <- orgtest$TargetBuy == orgtest$pred #create a new colum, TRUE if predicted = actual, otherwise FALSE
testcorrectcount <- length(which(orgtest$correct))
testincorrectcount <- nrow(orgtest) - testcorrectcount
testerrorrate <- testincorrectcount/nrow(orgtest)
testaccuracy <- 1-testerrorrate
orgtest <- testModelPerformance(orgtree, orgtest, orgtest$TargetBuy)
paste("TRAIN: Error Rate (", trainerrorrate, ") Accuracy (", trainaccuracy, ")")
paste("TEST: Error Rate (", testerrorrate, ") Accuracy (", testaccuracy, ")")
random <- runif(nrow(organics)) # create random numbers
orgrandom <- organics[order(random), ]
#Randomize the data
#Randomize the data
#Randomize the data
random <- runif(nrow(organics)) # create random numbers
orgrandom <- organics[order(random), ]
head(orgrandom)
orgtrain <- orgrandom[1:11110, ]
orgtest <- orgrandom[11111:22223, ]
table(orgtrain$TargetBuy)
orgtree <- rpart(TargetBuy ~ DemAffl+DemAge+DemClusterGroup+DemGender+DemReg+DemTVReg+PromClass+PromSpend+PromTime, data = orgtrain, method = "class")
orgtree
printcp(orgtree)
plotcp(orgtree)
rpart.plot(orgtree)
orgtrain <- testModelPerformance(orgtree, orgtrain, orgtrain$TargetBuy)
orgtest <- testModelPerformance(orgtree, orgtest, orgtest$TargetBuy)
orgtrain$treepred <- NULL
orgtrain$treepredcorrect <- NULL
orglogit <- glm(TargetBuy ~ DemAffl+DemAge+DemClusterGroup+DemGender+DemReg+DemTVReg+PromClass+PromSpend+PromTime, data = orgtrain,family = binomial(link='logit'))
summary(orglogit)
orglogit <- glm(TargetBuy ~ DemAge+DemGender+DemAffl+PromTime, data=orgtrain,family= binomial(link='logit'))
summary(orglogit)
confint.default(orglogit)
exp(coef(orglogit))
devdiff <- with(orglogit, null.deviance - deviance) #difference in deviance between null and this model
dofdiff <- with(orglogit, df.null - df.residual) #difference in degrees of freedom between null and this model
pval <- pchisq(devdiff, dofdiff, lower.tail = FALSE )
paste("Chi-Square: ", devdiff, " df: ", dofdiff, " p-value: ", pval)
orgtrain$probbuy <- predict(orglogit, newdata = orgtrain, type = "response")
resid.dev <- 2 * llh(orgtrain$TargetBuy, orgtrain$probbuy)
null.dev <- 2 * llh(orgtrain$TargetBuy, mean(orgtrain$TargetBuy))
pr2 <- 1-(resid.dev/null.dev)
paste("Psuedo R2: ", pr2)
head(orgtrain)
orgtrain$logitpred <- round(orgtrain$probbuy)
head(orgtrain)
orgtest$probbuy <- predict(orglogit, newdata = orgtest, type = "response")
orgtest$logitpred <- round(orgtest$probbuy)
orgtrain <- testModelPerformance(orglogit, orgtrain, orgtrain$TargetBuy, orgtrain$logitpred)
orgtest <- testModelPerformance(orglogit, orgtest, orgtest$TargetBuy, orgtest$logitpred)
random <- runif(nrow(organics)) # create random numbers
orgrandom <- organics[order(random), ]
head(orgrandom)
orgtrain <- orgrandom[1:15556, ]
orgtest <- orgrandom[15557:22223, ]
orgtree <- rpart(TargetBuy ~ DemAffl+DemAge+DemClusterGroup+DemGender+DemReg+DemTVReg+PromClass+PromSpend+PromTime, data = orgtrain, method = "class")
rpart.plot(orgtree)
orgtrain$pred <- predict(orgtree, orgtrain, type = "class") #create a prediction using our tree
table(Actual = orgtrain$TargetBuy, Predicted = orgtrain$pred) #create a confusion matrix
orgtrain$correct <- orgtrain$TargetBuy == orgtrain$pred #create a new colum, TRUE if predicted = actual, otherwise FALSE
traincorrectcount <- length(which(orgtrain$correct))
trainincorrectcount <- nrow(orgtrain) - traincorrectcount
trainerrorrate <- trainincorrectcount/nrow(orgtrain)
trainaccuracy <- 1-trainerrorrate
orgtest$pred <- predict(orgtree, orgtest, type = "class") #create a prediction using our tree
table(Actual = orgtest$TargetBuy, Predicted = orgtest$pred) #create a confusion matrix
orgtest$correct <- orgtest$TargetBuy == orgtest$pred #create a new colum, TRUE if predicted = actual, otherwise FALSE
testcorrectcount <- length(which(orgtest$correct))
testincorrectcount <- nrow(orgtest) - testcorrectcount
testerrorrate <- testincorrectcount/nrow(orgtest)
testaccuracy <- 1-testerrorrate
paste("TRAIN: Error Rate (", trainerrorrate, ") Accuracy (", trainaccuracy, ")")
paste("TEST: Error Rate (", testerrorrate, ") Accuracy (", testaccuracy, ")")
orgtrain <- testModelPerformance(orglogit, orgtrain, orgtrain$TargetBuy, orgtrain$logitpred)
orgtest <- testModelPerformance(orglogit, orgtest, orgtest$TargetBuy, orgtest$logitpred)
random <- runif(nrow(organics)) # create random numbers
orgrandom <- organics[order(random), ]
head(orgrandom)
orgtrain <- orgrandom[1:11110, ]
orgtest <- orgrandom[11111:22223, ]
table(orgtrain$TargetBuy)
orgtree <- rpart(TargetBuy ~ DemAffl+DemAge+DemClusterGroup+DemGender+DemReg+DemTVReg+PromClass+PromSpend+PromTime, data = orgtrain, method = "class")
orgtree
printcp(orgtree)
plotcp(orgtree)
rpart.plot(orgtree)
orgtrain <- testModelPerformance(orgtree, orgtrain, orgtrain$TargetBuy)
orgtest <- testModelPerformance(orgtree, orgtest, orgtest$TargetBuy)
orgtrain$treepred <- NULL
orgtrain$treepredcorrect <- NULL
orglogit <- glm(TargetBuy ~ DemAffl+DemAge+DemClusterGroup+DemGender+DemReg+DemTVReg+PromClass+PromSpend+PromTime, data = orgtrain,family = binomial(link='logit'))
summary(orglogit)
orglogit <- glm(TargetBuy ~ DemAge+DemGender+DemAffl+PromTime, data=orgtrain,family= binomial(link='logit'))
summary(orglogit)
confint.default(orglogit)
exp(coef(orglogit))
devdiff <- with(orglogit, null.deviance - deviance) #difference in deviance between null and this model
dofdiff <- with(orglogit, df.null - df.residual) #difference in degrees of freedom between null and this model
pval <- pchisq(devdiff, dofdiff, lower.tail = FALSE )
paste("Chi-Square: ", devdiff, " df: ", dofdiff, " p-value: ", pval)
orgtrain$probbuy <- predict(orglogit, newdata = orgtrain, type = "response")
resid.dev <- 2 * llh(orgtrain$TargetBuy, orgtrain$probbuy)
null.dev <- 2 * llh(orgtrain$TargetBuy, mean(orgtrain$TargetBuy))
pr2 <- 1-(resid.dev/null.dev)
paste("Psuedo R2: ", pr2)
head(orgtrain)
orgtrain$logitpred <- round(orgtrain$probbuy)
head(orgtrain)
orgtest$probbuy <- predict(orglogit, newdata = orgtest, type = "response")
orgtest$logitpred <- round(orgtest$probbuy)
orgtrain <- testModelPerformance(orglogit, orgtrain, orgtrain$TargetBuy, orgtrain$logitpred)
orgtest <- testModelPerformance(orglogit, orgtest, orgtest$TargetBuy, orgtest$logitpred)
install.packages("Rserve")
library(Rserve)
library(readtext)
q()
install.packages("syuzhet")
library('syuzhet')
install.packages("DBI")
library(DBI)
install.packages("sentiment")
library('forecast')
library('ggplot2')
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA")
getwd()
data=read.csv("samsung_sales.csv")
head(data)
summary(data)
data=ts(data[,2],frequency=4, start=c(2010,1),end=c(2015,4))
plot(data,xlab='Months',ylab='Sales')
#check if data is stationary
plot(diff(data),ylab='Sales of product')
library(tseries)
adf.test(data) # p-value < 0.05 indicates the TS is stationary
kpss.test(data)
#IF NOT STATIONARY DO THIS
plot(diff(log10(data)),ylab='Differenced Log (Sales)')
par(mfrow = c(1,2))
acf(ts(diff(data)),main='ACF Sales')
pacf(ts(diff(data)),main='PACF Sales')
require(forecast)
ARIMAfit = auto.arima(log10(data), approximation=FALSE,trace=FALSE)
summary(ARIMAfit)
#Predict sales for the next year
par(mfrow = c(1,1))
pred = predict(ARIMAfit, n.ahead = 4)
pred
library(xlsx)
write.xlsx(data,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata1.xlsx")
write.xlsx(pred,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata2.xlsx")
plot(data, type='l', xlim=c(2010,2017), ylim=c(1,200), xlab='Year',ylab='Sales')
lines(10^(pred$pred),col='blue')
lines(10^(pred$pred+2*pred$se),col='orange')
lines(10^(pred$pred-2*pred$se),col='orange')
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA")
getwd()
data=read.csv("samsung_sales.csv")
head(data)
summary(data)
data=ts(data[,2],frequency=4, start=c(2010,1),end=c(2015,4))
plot(data,xlab='Months',ylab='Sales')
#check if data is stationary
plot(diff(data),ylab='Sales of product')
library(tseries)
adf.test(data) # p-value < 0.05 indicates the TS is stationary
kpss.test(data)
#IF NOT STATIONARY DO THIS
plot(diff(log10(data)),ylab='Differenced Log (Sales)')
par(mfrow = c(1,2))
acf(ts(diff(data)),main='ACF Sales')
pacf(ts(diff(data)),main='PACF Sales')
require(forecast)
ARIMAfit = auto.arima(log10(data), approximation=FALSE,trace=FALSE)
summary(ARIMAfit)
#Predict sales for the next year
par(mfrow = c(1,1))
pred = predict(ARIMAfit, n.ahead = 4)
pred
library(xlsx)
write.xlsx(data,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata1.xlsx")
write.xlsx(pred,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata2.xlsx")
library(xlsx)
write.xlsx(data,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata1.xlsx")
write.xlsx(pred,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata2.xlsx")
plot(data, type='l', xlim=c(2010,2017), ylim=c(1,200), xlab='Year',ylab='Sales')
lines(10^(pred$pred),col='blue')
lines(10^(pred$pred+2*pred$se),col='orange')
lines(10^(pred$pred-2*pred$se),col='orange')
par(mfrow=c(1,2))
acf(ts(ARIMAfit$residuals),main='ACF Residual')
pacf(ts(ARIMAfit$residuals),main='PACF Residual')
library('forecast')
library('ggplot2')
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA")
getwd()
data=read.csv("samsung_sales.csv")
head(data)
summary(data)
data=ts(data[,2],frequency=4, start=c(2010,1),end=c(2015,4))
plot(data,xlab='Months',ylab='Sales')
#check if data is stationary
plot(diff(data),ylab='Sales of product')
library(tseries)
adf.test(data) # p-value < 0.05 indicates the TS is stationary
kpss.test(data)
#IF NOT STATIONARY DO THIS
plot(diff(log10(data)),ylab='Differenced Log (Sales)')
#create autocorrelation factor (ACF) and partial autocorrelation factor (PACF) plots to identify patterns
par(mfrow = c(1,2))
acf(ts(diff(data)),main='ACF Sales')
pacf(ts(diff(data)),main='PACF Sales')
require(forecast)
ARIMAfit = auto.arima(log10(data), approximation=FALSE,trace=FALSE)
summary(ARIMAfit)
#Predict sales for the next year
par(mfrow = c(1,1))
pred = predict(ARIMAfit, n.ahead = 4)
pred
library(xlsx)
write.xlsx(data,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata1.xlsx")
write.xlsx(pred,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata2.xlsx")
plot(data, type='l', xlim=c(2010,2017), ylim=c(1,200), xlab='Year',ylab='Sales')
lines(10^(pred$pred),col='blue')
lines(10^(pred$pred+2*pred$se),col='orange')
lines(10^(pred$pred-2*pred$se),col='orange')
############
#Confirm model fit  by recreating the ACF PACF plot
par(mfrow=c(1,2))
acf(ts(ARIMAfit$residuals),main='ACF Residual')
pacf(ts(ARIMAfit$residuals),main='PACF Residual')
library('forecast')
library('ggplot2')
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA")
getwd()
data=read.csv("samsung_sales.csv")
head(data)
summary(data)
data=read.csv("samsung_sales.csv")
head(data)
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA")
getwd()
data=read.csv("samsung_sales.csv")
head(data)
summary(data)
data=ts(data[,2],frequency=4, start=c(2010,1),end=c(2015,4))
plot(data,xlab='Months',ylab='Sales')
#check if data is stationary
plot(diff(data),ylab='Sales of product')
library(tseries)
adf.test(data) # p-value < 0.05 indicates the TS is stationary
kpss.test(data)
#IF NOT STATIONARY DO THIS
plot(diff(log10(data)),ylab='Differenced Log (Sales)')
par(mfrow = c(1,2))
acf(ts(diff(data)),main='ACF Sales')
pacf(ts(diff(data)),main='PACF Sales')
require(forecast)
ARIMAfit = auto.arima(log10(data), approximation=FALSE,trace=FALSE)
summary(ARIMAfit)
#Predict sales for the next year
par(mfrow = c(1,1))
pred = predict(ARIMAfit, n.ahead = 4)
pred
library(xlsx)
write.xlsx(data,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata1.xlsx")
library('forecast')
library('ggplot2')
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA")
getwd()
data=read.csv("samsung_sales.csv")
head(data)
summary(data)
data=ts(data[,2],frequency=4, start=c(2010,1),end=c(2015,4))
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA")
getwd()
data=read.csv("samsung_sales.csv")
head(data)
summary(data)
data=ts(data[,2],frequency=4, start=c(2010,1),end=c(2015,4))
plot(data,xlab='Months',ylab='Sales')
#check if data is stationary
plot(diff(data),ylab='Sales of product')
library(tseries)
adf.test(data) # p-value < 0.05 indicates the TS is stationary
kpss.test(data)
#IF NOT STATIONARY DO THIS
plot(diff(log10(data)),ylab='Differenced Log (Sales)')
par(mfrow = c(1,2))
acf(ts(diff(data)),main='ACF Sales')
pacf(ts(diff(data)),main='PACF Sales')
require(forecast)
ARIMAfit = auto.arima(log10(data), approximation=FALSE,trace=FALSE)
summary(ARIMAfit)
#Predict sales for the next year
par(mfrow = c(1,1))
pred = predict(ARIMAfit, n.ahead = 4)
pred
summary(ARIMAfit)
library(xlsx)
write.xlsx(ARIMAfit,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata1.xlsx")
write.xlsx(data,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata1.xlsx")
write.xlsx(pred,"C:\\Users\\Aishvarya\\Desktop\\R analysis\\ARIMA\\mydata2.xlsx")
plot(data, type='l', xlim=c(2010,2017), ylim=c(1,200), xlab='Year',ylab='Sales')
lines(10^(pred$pred),col='blue')
lines(10^(pred$pred+2*pred$se),col='orange')
lines(10^(pred$pred-2*pred$se),col='orange')
par(mfrow=c(1,2))
install.packages("survival")
install.packages("KMsurv")
library(survival)
library(KMsurv)
setwd("\\Learn R\\Surv")
wsurv.data <- read.csv("wealth_survival.csv",
stringsAsFactors = F
)
names <-names(wsurv.data )
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\Cox")
wsurv.data <- read.csv("wealth_survival.csv",stringsAsFactors = F)
names <-names(wsurv.data )
head(wsurv.data[,c(3,4,9,11,12)],10)
library(survival)
library(KMsurv)
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\Cox")
wsurv.data <- read.csv("wealth_survival.csv",stringsAsFactors = F)
names <-names(wsurv.data )
head(wsurv.data[,c(3,4,9,11,12)],10)
library(survival)
library(KMsurv)
w.surv <- survfit(Surv(wsurv.data$Time2Event, wsurv.data$attrition)~ 1, conf.type="none")
sum.surv <-summary(w.surv)
surv.out.df <- data.frame("Time" =sum.surv[[2]],
"Cust-Available"=sum.surv[[3]],
"Cust-Attrited"=sum.surv[[4]],
"Survival-Rate"=sum.surv[[6]])
write.csv(file="surv.csv",surv.out.df )
plot(w.surv,
xlab="Days since start",
ylab="Survival Rate",
main="Survival Rate at different time point")
w.surv.gender <- survfit(Surv(wsurv.data$Time2Event, wsurv.data$attrition)~ wsurv.data$GENDER, conf.type="none")
plot(w.surv.gender ,
xlab="Days since start",
ylab="Survival Rate",
main="Survival Rate by Gender",
lwd=2,
col=c("red","green"))
legend(30, .5, c("Female", "Male"),lwd=2,col=c("red","green"))
gender.surv <- survdiff(Surv(wsurv.data$Time2Event, wsurv.data$attrition)~ wsurv.data$GENDER,)
gender.surv
data <- read.csv("wealth_survival.csv",stringsAsFactors = F)
names <-names(data)
head(data)
survival <- survfit(Surv(wsurv.data$Time2Event, wsurv.data$attrition)~ 1, conf.type="none")
sum.surv <-summary(w.surv)
sum.surv <-summary(survival)
data <- read.csv("wealth_survival.csv",stringsAsFactors = F)
names <-names(data)
head(data)
survival <- survfit(Surv(wsurv.data$Time2Event, wsurv.data$attrition)~ 1, conf.type="none")
sum.survival <-summary(survival)
survival.out.df <- data.frame("Time" =sum.survival[[2]],
"Cust-Available"=sum.survival[[3]],
"Cust-Attrited"=sum.survival[[4]],
"Survival-Rate"=sum.survival[[6]])
write.csv(file="survival.csv",surv.out.df )
plot(survival,
xlab="Days since start",
ylab="Survival Rate",
main="Survival Rate at different time point")
data <- read.csv("wealth_survival.csv",stringsAsFactors = F)
names <-names(data)
head(data)
w.surv <- survfit(Surv(data$Time2Event, wsurv.data$attrition)~ 1, conf.type="none")
sum.surv <-summary(w.surv)
surv.out.df <- data.frame("Time" =sum.surv[[2]],
"Cust-Available"=sum.surv[[3]],
"Cust-Attrited"=sum.surv[[4]],
"Survival-Rate"=sum.surv[[6]])
write.csv(file="surv.csv",surv.out.df )
write.csv(file="survival.csv",surv.out.df )
plot(survival,
xlab="Days since start",
ylab="Survival Rate",
main="Survival Rate at different time point")
survival.gender <- survfit(Surv(wsurv.data$Time2Event, wsurv.data$attrition)~ wsurv.data$GENDER, conf.type="none")
survival.gender <- survfit(Surv(data$Time2Event, wsurv.data$attrition)~ wsurv.data$GENDER, conf.type="none")
plot(w.surv.gender ,
xlab="Days since start",
ylab="Survival Rate",
main="Survival Rate by Gender",
lwd=2,
col=c("red","green"))
legend(30, .5, c("Female", "Male"),lwd=2,col=c("red","green"))
gender.surv <- survdiff(Surv(wsurv.data$Time2Event, wsurv.data$attrition)~ wsurv.data$GENDER,)
gender.surv
plot(survival,
xlab="Days since start",
ylab="Survival Rate",
main="Survival Rate at different time point")
plot(w.surv,
xlab="Days since start",
ylab="Survival Rate",
main="Survival Rate at different time point")
