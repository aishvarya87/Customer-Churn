if (ts == 5) {bigT <- 250}
coefs              <- rep(0,simn)
rejections_vcov    <- 0
rejections_newey   <- 0
for (isim in 1:simn) {
# create random data
x                <- rnorm(bigT+100,mean=0,sd=xsd*sqrt(1-rhox*rhox))
e                <- rnorm(bigT+100,mean=0,sd=sig*sqrt(1-rho*rho))
for (t in 2:(bigT+100)) {
x[t]           <- rhox*x[t-1]  + x[t]
e[t]           <- rho*e[t-1]   + e[t]
}
x                <- x[101:(bigT+100)] + xmean
e                <- e[101:(bigT+100)]
y                <- b0 + b1*x + e
# estimate the ols coefficients
bhat             <- coef(lm(y~x)) #OLS coefficient
coefs[isim]      <- bhat[2]
model            <- lm((y-3-2*x)~x) #Testing if Ho:b1==2
ctest            <- coeftest(model)
if(ctest[2,4] < 0.05) rejections_vcov <- rejections_vcov   + 1
ctest            <- coeftest(model,vcov=NeweyWest(model,lag=5))  #Newey-West standard error correction
if(ctest[2,4] < 0.05) rejections_newey <- rejections_newey + 1
}
outp[ts,] <- c(bigT,mean(coefs),var(coefs),rejections_vcov/simn,rejections_newey/simn)
plot(density(coefs),xlim=c(1.5,2.5))
if(ts!=5)invisible(readline(prompt="Press [enter] to continue"))
}
if (ts == 1) {bigT <- 10}
if (ts == 2) {bigT <- 25}
if (ts == 3) {bigT <- 50}
if (ts == 4) {bigT <- 100}
if (ts == 5) {bigT <- 250}
rsq              <- rep(0,simn)
for (isim in 1:simn) {
# if (isim%%(simn/100)==0) print(isim/simn)
# create random data
x                <- rnorm(bigT+100)
y                <- rnorm(bigT+100)
# x                <- cumsum(x)
# y                <- cumsum(y)
x                <- x[101:(bigT+100)]
y                <- y[101:(bigT+100)]
## estimate the R-squared
# rsq[isim]      <- summary(lm(y~x))$r.squared
## first differences
# dx               <- diff(x)
# dy               <- diff(y)
# rsq[isim]        <- summary(lm(dy~dx))$r.squared
## second independent variable
# z                <- rnorm(bigT+100)
# z                <- cumsum(z)
# z                <- z[101:(bigT+100)]
# rsq[isim]        <- summary(lm(y~x+z))$r.squared
}
plot(density(rsq))
if(ts!=5)invisible(readline(prompt="Press [enter] to continue"))
}
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'rzQLiaeBfDzXTiYZbdhF0fiHM'
api_secret = 'Tcc13D6083iCXd1nEK0wHf4PZGbm8XtgaTRNPNwgTuxXGXzjIn'
access_token = '103206999-6UwDo8kaSGXFS4gKlAhMNiHskqrHhxFlc64li2sl'
access_token_secret = 'wsyoXIyggZL04mRQoLZVjY8DxRgJD80HPAprEtcXXuh70'
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
tweets=data.matrix(some_txt)
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
tweets=data.matrix(some_txt)
# function to get various sentiment scores, using the syuzhet package
scoreSentiment = function(tab)
{
tab$syuzhet = get_sentiment(tab$Text, method="syuzhet")
tab$bing = get_sentiment(tab$Text, method="bing")
tab$afinn = get_sentiment(tab$Text, method="afinn")
tab$nrc = get_sentiment(tab$Text, method="nrc")
emotions = get_nrc_sentiment(tab$Text)
n = names(emotions)
for (nn in n) tab[, nn] = emotions[nn]
return(tab)
}
# function to get various sentiment scores, using the syuzhet package
scoreSentiment = function(tab)
{
tab$syuzhet = get_sentiment(tab$Text, method="syuzhet")
tab$bing = get_sentiment(tab$Text, method="bing")
tab$afinn = get_sentiment(tab$Text, method="afinn")
tab$nrc = get_sentiment(tab$Text, method="nrc")
emotions = get_nrc_sentiment(tab$Text)
n = names(emotions)
for (nn in n) tab[, nn] = emotions[nn]
return(tab)
}
# get the sentiment scores for the tweets
tweets = scoreSentiment(tweets)
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
tweets=data.frame(some_txt)
# function to get various sentiment scores, using the syuzhet package
scoreSentiment = function(tab)
{
tab$syuzhet = get_sentiment(tab$Text, method="syuzhet")
tab$bing = get_sentiment(tab$Text, method="bing")
tab$afinn = get_sentiment(tab$Text, method="afinn")
tab$nrc = get_sentiment(tab$Text, method="nrc")
emotions = get_nrc_sentiment(tab$Text)
n = names(emotions)
for (nn in n) tab[, nn] = emotions[nn]
return(tab)
}
# function to get various sentiment scores, using the syuzhet package
scoreSentiment = function(tab)
{
tab$syuzhet = get_sentiment(tab$Text, method="syuzhet")
tab$bing = get_sentiment(tab$Text, method="bing")
tab$afinn = get_sentiment(tab$Text, method="afinn")
tab$nrc = get_sentiment(tab$Text, method="nrc")
emotions = get_nrc_sentiment(tab$Text)
n = names(emotions)
for (nn in n) tab[, nn] = emotions[nn]
return(tab)
}
# get the sentiment scores for the tweets
tweets = scoreSentiment(tweets)
tweets=data.frame(some_txt, stringsAsFactors = False)
tweets=data.frame(some_txt, stringsAsFactors = FALSE)
# function to get various sentiment scores, using the syuzhet package
scoreSentiment = function(tab)
{
tab$syuzhet = get_sentiment(tab$Text, method="syuzhet")
tab$bing = get_sentiment(tab$Text, method="bing")
tab$afinn = get_sentiment(tab$Text, method="afinn")
tab$nrc = get_sentiment(tab$Text, method="nrc")
emotions = get_nrc_sentiment(tab$Text)
n = names(emotions)
for (nn in n) tab[, nn] = emotions[nn]
return(tab)
}
# get the sentiment scores for the tweets
tweets = scoreSentiment(tweets)
tweets=data.frame(some_txt, stringsAsFactors = FALSE, as.character(tweets[1,]))
# function to get various sentiment scores, using the syuzhet package
scoreSentiment = function(tab)
{
tab$syuzhet = get_sentiment(tab$Text, method="syuzhet")
tab$bing = get_sentiment(tab$Text, method="bing")
tab$afinn = get_sentiment(tab$Text, method="afinn")
tab$nrc = get_sentiment(tab$Text, method="nrc")
emotions = get_nrc_sentiment(tab$Text)
n = names(emotions)
for (nn in n) tab[, nn] = emotions[nn]
return(tab)
}
# get the sentiment scores for the tweets
tweets = scoreSentiment(tweets)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'rzQLiaeBfDzXTiYZbdhF0fiHM'
api_secret = 'Tcc13D6083iCXd1nEK0wHf4PZGbm8XtgaTRNPNwgTuxXGXzjIn'
access_token = '103206999-6UwDo8kaSGXFS4gKlAhMNiHskqrHhxFlc64li2sl'
access_token_secret = 'wsyoXIyggZL04mRQoLZVjY8DxRgJD80HPAprEtcXXuh70'
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
tweets = read.dbf('tweets.dbf', as.is = TRUE)
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
# remove retweet entities
some_txt = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', some_txt)
# remove at people
some_txt = gsub('@\\w+', '', some_txt)
# remove punctuation
some_txt = gsub('[[:punct:]]', '', some_txt)
# remove numbers
some_txt = gsub('[[:digit:]]', '', some_txt)
# remove html links
some_txt = gsub('http\\w+', '', some_txt)
# remove unnecessary spaces
some_txt = gsub('[ \t]{2,}', '', some_txt)
some_txt = gsub('^\\s+|\\s+$', '', some_txt)
# define 'tolower error handling' function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, 'error'))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
some_txt = sapply(some_txt, try.error)
# remove NAs in some_txt
some_txt = some_txt[!is.na(some_txt)]
names(some_txt) = NULL
# Perform Sentiment Analysis
# classify emotion
class_emo = classify_emotion(some_txt, algorithm='bayes', prior=1.0)
if (!require('pacman')) install.packages('pacman&')
pacman::p_load(devtools, installr)
install.Rtools()
install_url('http://cran.r-project.org/src/contrib/Archive/Rstem/Rstem_0.4-1.tar.gz')
install_url('http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz')
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'rzQLiaeBfDzXTiYZbdhF0fiHM'
api_secret = 'Tcc13D6083iCXd1nEK0wHf4PZGbm8XtgaTRNPNwgTuxXGXzjIn'
access_token = '103206999-6UwDo8kaSGXFS4gKlAhMNiHskqrHhxFlc64li2sl'
access_token_secret = 'wsyoXIyggZL04mRQoLZVjY8DxRgJD80HPAprEtcXXuh70'
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'rzQLiaeBfDzXTiYZbdhF0fiHM'
api_secret = 'Tcc13D6083iCXd1nEK0wHf4PZGbm8XtgaTRNPNwgTuxXGXzjIn'
access_token = '103206999-6UwDo8kaSGXFS4gKlAhMNiHskqrHhxFlc64li2sl'
access_token_secret = 'wsyoXIyggZL04mRQoLZVjY8DxRgJD80HPAprEtcXXuh70'
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'rzQLiaeBfDzXTiYZbdhF0fiHM'
api_secret = 'Tcc13D6083iCXd1nEK0wHf4PZGbm8XtgaTRNPNwgTuxXGXzjIn'
access_token = '103206999-6UwDo8kaSGXFS4gKlAhMNiHskqrHhxFlc64li2sl'
access_token_secret = 'wsyoXIyggZL04mRQoLZVjY8DxRgJD80HPAprEtcXXuh70'
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'rzQLiaeBfDzXTiYZbdhF0fiHM'
api_secret = 'Tcc13D6083iCXd1nEK0wHf4PZGbm8XtgaTRNPNwgTuxXGXzjIn'
access_token = '103206999-6UwDo8kaSGXFS4gKlAhMNiHskqrHhxFlc64li2sl'
access_token_secret = 'wsyoXIyggZL04mRQoLZVjY8DxRgJD80HPAprEtcXXuh70'
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
# remove retweet entities
some_txt = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', some_txt)
# remove at people
some_txt = gsub('@\\w+', '', some_txt)
# remove punctuation
some_txt = gsub('[[:punct:]]', '', some_txt)
# remove numbers
some_txt = gsub('[[:digit:]]', '', some_txt)
# remove html links
some_txt = gsub('http\\w+', '', some_txt)
# remove unnecessary spaces
some_txt = gsub('[ \t]{2,}', '', some_txt)
some_txt = gsub('^\\s+|\\s+$', '', some_txt)
# define 'tolower error handling' function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, 'error'))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
some_txt = sapply(some_txt, try.error)
# remove NAs in some_txt
some_txt = some_txt[!is.na(some_txt)]
names(some_txt) = NULL
# Perform Sentiment Analysis
# classify emotion
class_emo = classify_emotion(some_txt, algorithm='bayes', prior=1.0)
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer,
httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm, am, RStem)
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer,
httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm, am, Rstem)
install.packages(am)
install.packages("am")
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer,
httpuv, RCurl, openssl, base64enc, foreign, lubridate, tm, Rstem)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
if (!require('pacman')) install.packages('pacman&')
pacman::p_load(devtools, installr)
install.Rtools()
install_url('http://cran.r-project.org/src/contrib/Archive/Rstem/Rstem_0.4-1.tar.gz')
install_url('http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz')
api_key = 'rzQLiaeBfDzXTiYZbdhF0fiHM'
api_secret = 'Tcc13D6083iCXd1nEK0wHf4PZGbm8XtgaTRNPNwgTuxXGXzjIn'
access_token = '103206999-6UwDo8kaSGXFS4gKlAhMNiHskqrHhxFlc64li2sl'
access_token_secret = 'wsyoXIyggZL04mRQoLZVjY8DxRgJD80HPAprEtcXXuh70'
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=10000, lang='en')
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=5000, lang='en')
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
if (!require('pacman')) install.packages('pacman')
install.packages("SnowballC")
pacman::p_load(twitteR, syuzhet, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, openssl, base64enc, fpc, tm, NLP)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'rzQLiaeBfDzXTiYZbdhF0fiHM'
api_secret = 'Tcc13D6083iCXd1nEK0wHf4PZGbm8XtgaTRNPNwgTuxXGXzjIn'
access_token = '103206999-6UwDo8kaSGXFS4gKlAhMNiHskqrHhxFlc64li2sl'
access_token_secret = 'wsyoXIyggZL04mRQoLZVjY8DxRgJD80HPAprEtcXXuh70'
setup_twitter_oauth(api_key,api_secret, access_token, access_token_secret)
# harvest some tweets
some_tweets = searchTwitter('GalaxyS9', n=5000, lang='en')
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
# remove retweet entities
some_txt = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', some_txt)
# remove at people
some_txt = gsub('@\\w+', '', some_txt)
# remove punctuation
some_txt = gsub('[[:punct:]]', '', some_txt)
# remove numbers
some_txt = gsub('[[:digit:]]', '', some_txt)
# remove html links
some_txt = gsub('http\\w+', '', some_txt)
# remove unnecessary spaces
some_txt = gsub('[ \t]{2,}', '', some_txt)
some_txt = gsub('^\\s+|\\s+$', '', some_txt)
# define 'tolower error handling' function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, 'error'))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
some_txt = sapply(some_txt, try.error)
# remove NAs in some_txt
some_txt = some_txt[!is.na(some_txt)]
names(some_txt) = NULL
word<-get_nrc_sentiment(some_txt)
td<-data.frame(t(word))
td_new <- data.frame(rowSums(td[2:10000]))
td_new <- data.frame(rowSums(td[2:5000]))
#Transformation and  cleaning
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
library("ggplot2")
qplot(sentiment, data=td_new2, weight=count, geom="bar",fill=sentiment)+ggtitle("sentiments")
qplot(sentiment, data=td_new2, weight=count, geom="bar",fill=sentiment)+ggtitle("Sentiments Expressed for GalaxyS9 on Twitter - 3/2/2018")
# Separate the text by emotions and visualize the words with a comparison cloud
# separating text by emotion
emos = levels(factor(td_new2$emotion))
nemo = length(emos)
emo.docs = rep('', nemo)
for (i in 1:nemo)
{
tmp = some_txt[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=' ')
}
#####START FROM HERE######################################################################################
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\Sentiment Analysis")
getwd()
library(MASS)
library(plyr)
library(survival)
library(KMsurv)
library(ggplot2)
library(caret)
setwd("C:\\Users\\Aishvarya\\Desktop\\R analysis\\Cox\\telco")
getwd()
data<-read.csv("telco.csv")
names<-names(data)
head(data)
survival<-survfit(Surv(data$tenure, data$mychurn)~1, conf.type="none")
summ<-summary(survival)
df<-data.frame("Time"=summ[[2]],
"Customer-available"=summ[[3]],
"Customer-Attrited"=summ[[4]],
"Survival-Rate"=summ[[6]])
write.csv(file="output.csv",df)
plot(survival, xlab='Days since start',
ylab='Survival Rate',
main='Survival Rate at different timepoints')
##Gender##
survGender<-survfit(Surv(data$tenure, data$mychurn)~data$gender, conf.type="none")
plot(survGender, xlab='Days since start',
ylab='Survival Rate',
main='Survival Rate for Gender',
lwd=2,
col=c("Red","Blue"))
legend(30, .5, c("Female","Male"),lwd=2,col=c('red', 'blue'))
survContract<-survfit(Surv(data$tenure, data$mychurn)~data$Contract, conf.type="none")
plot(survContract, xlab='Days since start',
ylab='Survival Rate',
main='Survival Rate for Contract Type',
lwd=2,
col=c("Red","Blue","Green"))
legend(30, .5, c("M2M","1Year","2Year"),lwd=2,col=c('red', 'blue','green'))
##Monthly charges##
survGender<-survfit(Surv(data$MonthlyCharges, data$mychurn)~data$gender, conf.type="none")
plot(survGender, xlab='Days since start',
ylab='Survival Rate',
main='Survival Rate as per Monthly charges',
lwd=2,
col=c("Red","Blue"))
legend(30, .5, c("Female","Male"),lwd=2,col=c('red', 'blue'))
cox.ph.model<-coxph(Surv(tenure,mychurn)~MonthlyCharges, data=data)
summary(cox.ph.model)
cox.ph.model<-coxph(Surv(tenure,mychurn)~TotalCharges, data=data)
summary(cox.ph.model)
cox.ph.model<-coxph(Surv(tenure,mychurn)~Contract, data=data)
summary(cox.ph.model)
cox.ph.model<-coxph(Surv(tenure,mychurn)~Contract+Dependents, data=data)
summary(cox.ph.model)
cox.ph.model<-coxph(Surv(tenure,mychurn)~Contract+Dependents+MultipleLines+TechSupport+PaymentMethod, data=data)
summary(cox.ph.model)
base.hazard <- survfit(Surv(Time2Event, attrition)~1,
data=wsurv.data)
base.hazard <- survfit(Surv(tenure, mychurn)~1,
data=data)
basehaz(cox.ph.model)
cox.ph.model<-coxph(Surv(tenure,mychurn)~(Contract+Dependents+MultipleLines+TechSupport+PaymentMethod)*strata(Gender), data=data)
cox.ph.model<-coxph(Surv(tenure,mychurn)~(Contract+Dependents+MultipleLines+TechSupport+PaymentMethod)*strata(gender), data=data)
summary(cox.ph.model)
df_rf<-read.csv("telco.csv",stringsAsFactors = FALSE)
#check variable types
str(df_rf)
df_rf<-read.csv("telco.csv",stringsAsFactors = FALSE)
df_rf<-read.csv("telco.csv",stringsAsFactors = FALSE)
#check variable types
str(df_rf)
#Summary stats
summary(df_rf)
# Check Target Variable level - counts and %
table(df_rf$Spend_Drop_over50pct)
table(df_rf$Spend_Drop_over50pct)*100/nrow(df_rf)
# Name of  variables
names(df_rf)
# Check Target Variable level - counts and %
table(df_rf$churn)
table(df_rf$churn)*100/nrow(df_rf)
# Name of  variables
names(df_rf)
df_rf$Spend_Drop_over50pct <- as.factor(df_rf$Spend_Drop_over50pct)
df_rf$Tchurn <- as.factor(df_rf$churn)
#Summary stats
summary(df_rf)
# Check Target Variable level - counts and %
table(df_rf$Churn)
table(df_rf$Churn)*100/nrow(df_rf)
# Name of  variables
names(df_rf)
df_rf$TChurn <- as.factor(df_rf$Churn)
df_rf$Churn <- as.factor(df_rf$Churn)
df_rf<-read.csv("telco.csv",stringsAsFactors = FALSE)
#check variable types
str(df_rf)
#Summary stats
summary(df_rf)
# Check Target Variable level - counts and %
table(df_rf$Churn)
table(df_rf$Churn)*100/nrow(df_rf)
# Name of  variables
names(df_rf)
df_rf$Churn <- as.factor(df_rf$Churn)
# -----------------  Build Random Forest -----------------------------
library(randomForest)
rf_mod <- randomForest(Churn~MonthlyCharges+TotalCharges,
data =df_rf )
rf_mod <- randomForest(Churn~MonthlyCharges, data =df_rf )
# Save the Random Forest Model
saveRDS(rf_mod,file="rf_model")
# remove random forest model object from env
rm(rf_mod)
rf_mod
# Load Random Forest
rf_mod <-readRDS(file="rf_model")
summary(rf_mod)
